import { writeFileSync } from 'node:fs';
import { join } from 'node:path';
/**
 * Aivis Cloud API example for @aituber-onair/voice in Bun
 * This example demonstrates using Aivis Cloud API for text-to-speech.
 *
 * Requirements:
 * - Aivis Cloud API key (get from https://hub.aivis-project.com/cloud-api/api-keys)
 * - Internet connection
 * - Optional: speaker or play-sound for audio playback
 *
 * Run with: bun run aivis-cloud-example.js
 */
import { VoiceEngineAdapter } from '../../dist/cjs/index.js';

async function main() {
  console.log('=== AITuber OnAir Voice - Aivis Cloud API Bun Example ===\n');

  // Get API key from environment variable
  const apiKey = process.env.AIVIS_CLOUD_API_KEY;
  if (!apiKey) {
    console.error('âŒ AIVIS_CLOUD_API_KEY environment variable not set');
    console.log('\nğŸ“Œ To use Aivis Cloud API:');
    console.log(
      '1. Get API key from https://hub.aivis-project.com/cloud-api/api-keys',
    );
    console.log(
      '2. Set environment variable: export AIVIS_CLOUD_API_KEY="your-api-key"',
    );
    console.log('3. Run with: bun run aivis-cloud-example.js');
    console.log('\nâ­ï¸  Continuing with basic adapter test...\n');
  }

  // Basic Aivis Cloud configuration
  const aivisCloudOptions = {
    engineType: 'aivisCloud',
    speaker: 'a59cb814-0083-4369-8542-f51a29e72af7', // Example model UUID
    apiKey: apiKey || 'demo-key-for-adapter-test',
    onComplete: () => {
      console.log('âœ“ Speech processing completed');
    },
  };

  console.log('=== Test 1: Basic adapter creation ===');
  try {
    const voiceService = new VoiceEngineAdapter(aivisCloudOptions);
    console.log('âœ“ VoiceEngineAdapter created successfully');
    console.log(`âœ“ Using model UUID: ${aivisCloudOptions.speaker}`);
    console.log(`âœ“ API key configured: ${apiKey ? 'Yes' : 'No (demo mode)'}`);
    console.log(`âœ“ Running on Bun ${Bun.version}`);
    console.log();
  } catch (error) {
    console.error('âŒ Failed to create adapter:', error.message);
    return;
  }

  // Skip actual API calls if no API key is provided
  if (!apiKey) {
    console.log('âš ï¸  Skipping API tests (no API key provided)');
    console.log('âœ… Basic adapter test completed!');
    console.log('\nTo test actual speech generation:');
    console.log(
      '1. Get API key from https://hub.aivis-project.com/cloud-api/api-keys',
    );
    console.log('2. Set AIVIS_CLOUD_API_KEY environment variable');
    console.log('3. Run this example again');
    return;
  }

  // Test 2: High-performance text-to-speech
  console.log('=== Test 2: High-performance text-to-speech ===');
  try {
    const outputPath = join(import.meta.dir, 'aivis-cloud-basic.mp3');
    const startTime = performance.now();

    const voiceService = new VoiceEngineAdapter({
      ...aivisCloudOptions,
      onPlay: async (audioBuffer) => {
        console.log(
          `âœ“ Received audio buffer (${audioBuffer.byteLength} bytes)`,
        );
        writeFileSync(outputPath, Buffer.from(audioBuffer));
        const endTime = performance.now();
        const duration = Math.round(endTime - startTime);
        console.log(`âœ“ Audio saved to: ${outputPath} (${duration}ms)`);
      },
    });

    console.log('Generating speech with Aivis Cloud API (Bun optimized)...');
    await voiceService.speakText(
      'ã“ã‚“ã«ã¡ã¯ï¼Aivis Cloud APIã®Bunãƒ†ã‚¹ãƒˆã§ã™ã€‚é«˜é€Ÿå®Ÿè¡Œã‚’ãŠæ¥½ã—ã¿ãã ã•ã„ï¼',
    );
    console.log('âœ“ Test 2 passed\n');
  } catch (error) {
    console.error('âŒ Test 2 failed:', error.message);
    console.error('Check your API key and internet connection\n');
  }

  // Test 3: Bun's fast I/O with SSML
  console.log('=== Test 3: Fast I/O with SSML ===');
  try {
    const outputPath = join(import.meta.dir, 'aivis-cloud-ssml.mp3');
    const startTime = performance.now();

    const voiceService = new VoiceEngineAdapter({
      ...aivisCloudOptions,
      onPlay: async (audioBuffer) => {
        // Bun's optimized writeFileSync
        writeFileSync(outputPath, Buffer.from(audioBuffer));
        const endTime = performance.now();
        console.log(
          `âœ“ SSML audio saved (${Math.round(endTime - startTime)}ms): ${outputPath}`,
        );
      },
    });

    const ssmlText = `
      ã“ã‚“ã«ã¡ã¯ï¼<break time="0.4s"/>
      <prosody rate="115%" pitch="+3%">Bunã¯JavaScriptãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ä¸­ã§ã‚‚ç‰¹ã«é«˜é€Ÿã§ã™ã€‚</prosody>
      <break time="0.3s"/>
      <sub alias="ã‚¨ãƒ¼ã‚¢ã‚¤ãƒ“ã‚¹">Aivis</sub> Cloud APIã¨ã®çµ„ã¿åˆã‚ã›ã§æœ€é«˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
    `;

    console.log('Generating SSML-enhanced speech with Bun optimization...');
    await voiceService.speakText(ssmlText);
    console.log('âœ“ Test 3 passed\n');
  } catch (error) {
    console.error('âŒ Test 3 failed:', error.message, '\n');
  }

  // Test 4: Parallel processing demonstration
  console.log('=== Test 4: Parallel processing test ===');
  try {
    const texts = [
      'Bunã®ä¸¦åˆ—å‡¦ç†æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚',
      'ã“ã‚Œã¯2ç•ªç›®ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚',
      'ãã—ã¦3ç•ªç›®ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚',
    ];

    console.log(`Processing ${texts.length} texts in parallel...`);
    const startTime = performance.now();

    // Process all texts in parallel (Bun handles this efficiently)
    const promises = texts.map(async (text, index) => {
      const outputPath = join(
        import.meta.dir,
        `aivis-cloud-parallel-${index + 1}.mp3`,
      );

      const voiceService = new VoiceEngineAdapter({
        engineType: 'aivisCloud',
        speaker: 'a59cb814-0083-4369-8542-f51a29e72af7',
        apiKey: apiKey,
        aivisCloudOutputFormat: 'mp3',
        aivisCloudSpeakingRate: 1.0 + index * 0.1,
        onPlay: async (audioBuffer) => {
          writeFileSync(outputPath, Buffer.from(audioBuffer));
          console.log(
            `âœ“ Parallel ${index + 1}/${texts.length} saved: aivis-cloud-parallel-${index + 1}.mp3`,
          );
        },
      });

      return voiceService.speakText(text);
    });

    await Promise.all(promises);
    const endTime = performance.now();
    const totalDuration = Math.round(endTime - startTime);

    console.log(
      `âœ“ All ${texts.length} texts processed in parallel (${totalDuration}ms total)`,
    );
    console.log('âœ“ Test 4 passed\n');
  } catch (error) {
    console.error('âŒ Test 4 failed:', error.message, '\n');
  }

  // Test 5: Format and performance comparison
  console.log('=== Test 5: Format performance benchmark ===');
  const formats = [
    { format: 'mp3', description: 'MP3 - Universal compatibility' },
    { format: 'aac', description: 'AAC - Better compression' },
    { format: 'flac', description: 'FLAC - Lossless compression' },
    { format: 'wav', description: 'WAV - Uncompressed quality' },
  ];

  const benchmarkResults = [];

  for (const { format, description } of formats) {
    try {
      const startTime = performance.now();
      const outputPath = join(import.meta.dir, `aivis-cloud-format.${format}`);

      const voiceService = new VoiceEngineAdapter({
        engineType: 'aivisCloud',
        speaker: 'a59cb814-0083-4369-8542-f51a29e72af7',
        apiKey: apiKey,
        aivisCloudOutputFormat: format,
        onPlay: async (audioBuffer) => {
          writeFileSync(outputPath, Buffer.from(audioBuffer));
        },
      });

      await voiceService.speakText(
        `ã“ã‚Œã¯${format}å½¢å¼ã®Bunãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆã§ã™ã€‚`,
      );
      const endTime = performance.now();
      const duration = Math.round(endTime - startTime);

      benchmarkResults.push({
        format: format.toUpperCase(),
        duration,
        description,
      });
      console.log(`âœ“ ${format.toUpperCase()}: ${duration}ms - ${description}`);
    } catch (error) {
      console.error(`âŒ Failed for ${format}:`, error.message);
    }
  }

  // Show benchmark summary
  console.log('\nğŸ“Š Performance Summary:');
  benchmarkResults
    .sort((a, b) => a.duration - b.duration)
    .forEach((result, index) => {
      const medal =
        index === 0 ? 'ğŸ¥‡' : index === 1 ? 'ğŸ¥ˆ' : index === 2 ? 'ğŸ¥‰' : '  ';
      console.log(`${medal} ${result.format}: ${result.duration}ms`);
    });

  console.log('\n=== Summary ===');
  console.log('âœ… Aivis Cloud API Bun example completed!');
  console.log('\nâ„¹ï¸  Bun performance advantages:');
  console.log('- âœ… Faster startup time than Node.js');
  console.log('- âœ… Optimized file I/O operations');
  console.log('- âœ… Built-in bundler and package manager');
  console.log('- âœ… Native fetch() without polyfills');
  console.log('- âœ… Excellent parallel processing');
  console.log('- âœ… TypeScript support out of the box');
  console.log('\nâ„¹ï¸  Generated files can be played with:');
  console.log('- macOS: afplay filename.mp3');
  console.log('- Linux: aplay filename.wav');
  console.log('- Windows: start filename.mp3');
  console.log('\nğŸ”— More info: https://aivis-project.com/cloud-api/');
}

// Real-time streaming simulation
async function streamingSimulation() {
  console.log('\n=== Advanced Example: Real-time Streaming Simulation ===');

  const apiKey = process.env.AIVIS_CLOUD_API_KEY;
  if (!apiKey) {
    console.log('âš ï¸  Skipping streaming simulation (no API key)');
    return;
  }

  try {
    console.log('Simulating real-time streaming with chunk processing...');

    const chunks = [
      'ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã®',
      'ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™ã€‚',
      'Bunã®é«˜é€Ÿå‡¦ç†ã«ã‚ˆã‚Š',
      'ã‚¹ãƒ ãƒ¼ã‚ºãªéŸ³å£°ç”ŸæˆãŒå¯èƒ½ã§ã™ã€‚',
    ];

    for (let i = 0; i < chunks.length; i++) {
      const chunkStartTime = performance.now();
      const outputPath = join(
        import.meta.dir,
        `aivis-cloud-chunk-${i + 1}.mp3`,
      );

      const voiceService = new VoiceEngineAdapter({
        engineType: 'aivisCloud',
        speaker: 'a59cb814-0083-4369-8542-f51a29e72af7',
        apiKey: apiKey,
        aivisCloudOutputFormat: 'mp3',
        aivisCloudSpeakingRate: 1.1,
        onPlay: async (audioBuffer) => {
          writeFileSync(outputPath, Buffer.from(audioBuffer));
          const chunkEndTime = performance.now();
          const chunkDuration = Math.round(chunkEndTime - chunkStartTime);
          console.log(
            `âœ“ Chunk ${i + 1}/${chunks.length}: ${chunkDuration}ms - ${outputPath}`,
          );
        },
      });

      await voiceService.speakText(chunks[i]);

      // Small delay to simulate real-time processing
      if (i < chunks.length - 1) {
        await new Promise((resolve) => setTimeout(resolve, 100));
      }
    }

    console.log('âœ… Streaming simulation completed!');
    console.log(
      'â„¹ï¸  In a real application, these chunks could be played sequentially for continuous audio',
    );
  } catch (error) {
    console.error('âŒ Streaming simulation failed:', error.message);
  }
}

// Run examples
async function runAll() {
  await main();
  await streamingSimulation();
}

if (import.meta.main) {
  runAll().catch(console.error);
}
