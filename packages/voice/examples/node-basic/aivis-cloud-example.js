/**
 * Aivis Cloud API example for @aituber-onair/voice in Node.js
 * This example demonstrates using Aivis Cloud API for text-to-speech.
 *
 * Requirements:
 * - Aivis Cloud API key (get from https://hub.aivis-project.com/cloud-api/api-keys)
 * - Internet connection
 * - Optional: npm install speaker OR npm install play-sound for audio playback
 */
const { VoiceEngineAdapter } = require('../../dist/cjs/index.js');
const fs = require('node:fs');
const path = require('node:path');

async function main() {
  console.log('=== AITuber OnAir Voice - Aivis Cloud API Example ===\n');

  // Get API key from environment variable or prompt user
  const apiKey = process.env.AIVIS_CLOUD_API_KEY;
  if (!apiKey) {
    console.error('âŒ AIVIS_CLOUD_API_KEY environment variable not set');
    console.log('\nğŸ“Œ To use Aivis Cloud API:');
    console.log(
      '1. Get API key from https://hub.aivis-project.com/cloud-api/api-keys',
    );
    console.log(
      '2. Set environment variable: export AIVIS_CLOUD_API_KEY="your-api-key"',
    );
    console.log('3. Run this example again');
    console.log('\nâ­ï¸  Continuing with basic adapter test...\n');
  }

  // Basic Aivis Cloud configuration
  const aivisCloudOptions = {
    engineType: 'aivisCloud',
    speaker: 'a59cb814-0083-4369-8542-f51a29e72af7', // Example model UUID
    apiKey: apiKey || 'demo-key-for-adapter-test',
    onComplete: () => {
      console.log('âœ“ Speech processing completed');
    },
  };

  console.log('=== Test 1: Basic adapter creation ===');
  try {
    const voiceService = new VoiceEngineAdapter(aivisCloudOptions);
    console.log('âœ“ VoiceEngineAdapter created successfully');
    console.log(`âœ“ Using model UUID: ${aivisCloudOptions.speaker}`);
    console.log(`âœ“ API key configured: ${apiKey ? 'Yes' : 'No (demo mode)'}`);
    console.log();
  } catch (error) {
    console.error('âŒ Failed to create adapter:', error.message);
    return;
  }

  // Skip actual API calls if no API key is provided
  if (!apiKey) {
    console.log('âš ï¸  Skipping API tests (no API key provided)');
    console.log('âœ… Basic adapter test completed!');
    console.log('\nTo test actual speech generation:');
    console.log(
      '1. Get API key from https://hub.aivis-project.com/cloud-api/api-keys',
    );
    console.log('2. Set AIVIS_CLOUD_API_KEY environment variable');
    console.log('3. Run this example again');
    return;
  }

  // Test 2: Basic text-to-speech with file output
  console.log('=== Test 2: Basic text-to-speech ===');
  try {
    const outputPath = path.join(__dirname, 'aivis-cloud-basic.mp3');

    const voiceService = new VoiceEngineAdapter({
      ...aivisCloudOptions,
      onPlay: async (audioBuffer) => {
        console.log(
          `âœ“ Received audio buffer (${audioBuffer.byteLength} bytes)`,
        );
        fs.writeFileSync(outputPath, Buffer.from(audioBuffer));
        console.log(`âœ“ Audio saved to: ${outputPath}`);
      },
    });

    console.log('Generating speech with Aivis Cloud API...');
    await voiceService.speakText(
      'ã“ã‚“ã«ã¡ã¯ï¼Aivis Cloud APIã®éŸ³å£°åˆæˆãƒ†ã‚¹ãƒˆã§ã™ã€‚',
    );
    console.log('âœ“ Test 2 passed\n');
  } catch (error) {
    console.error('âŒ Test 2 failed:', error.message);
    console.error('Check your API key and internet connection\n');
  }

  // Test 3: SSML example
  console.log('=== Test 3: SSML support test ===');
  try {
    const outputPath = path.join(__dirname, 'aivis-cloud-ssml.mp3');

    const voiceService = new VoiceEngineAdapter({
      ...aivisCloudOptions,
      onPlay: async (audioBuffer) => {
        fs.writeFileSync(outputPath, Buffer.from(audioBuffer));
        console.log(`âœ“ SSML audio saved to: ${outputPath}`);
      },
    });

    const ssmlText = `
      ã“ã‚“ã«ã¡ã¯ï¼<break time="0.5s"/>
      <prosody rate="110%" pitch="+5%">ã“ã‚Œã¯SSMLã‚¿ã‚°ã‚’ä½¿ã£ãŸä¾‹ã§ã™ã€‚</prosody>
      <break time="0.3s"/>
      <sub alias="ã‚¨ãƒ¼ã‚¢ã‚¤ãƒ“ã‚¹">Aivis</sub> Cloud APIã¯é«˜å“è³ªãªéŸ³å£°åˆæˆã‚’æä¾›ã—ã¾ã™ã€‚
    `;

    console.log('Generating SSML-enhanced speech...');
    await voiceService.speakText(ssmlText);
    console.log('âœ“ Test 3 passed\n');
  } catch (error) {
    console.error('âŒ Test 3 failed:', error.message, '\n');
  }

  // Test 4: Advanced configuration with emotional intensity
  console.log('=== Test 4: Advanced configuration ===');
  try {
    const emotions = [
      {
        emotion: 'happy',
        intensity: 1.2,
        text: 'å¬‰ã—ã„ã§ã™ï¼Aivis Cloud APIã§æ„Ÿæƒ…è±Šã‹ã«è©±ã—ã¾ã™ï¼',
      },
      {
        emotion: 'sad',
        intensity: 0.8,
        text: 'å°‘ã—æ‚²ã—ã’ã«ã€é™ã‹ã«è©±ã—ã¦ã¿ã¾ã™ã€‚',
      },
      {
        emotion: 'normal',
        intensity: 1.0,
        text: 'é€šå¸¸ã®æ„Ÿæƒ…ã§è‡ªç„¶ã«è©±ã—ã¾ã™ã€‚',
      },
    ];

    for (const { emotion, intensity, text } of emotions) {
      const outputPath = path.join(__dirname, `aivis-cloud-${emotion}.mp3`);

      // Create service with advanced options
      const voiceService = new VoiceEngineAdapter({
        engineType: 'aivisCloud',
        speaker: 'a59cb814-0083-4369-8542-f51a29e72af7',
        apiKey: apiKey,
        aivisCloudEmotionalIntensity: intensity,
        aivisCloudOutputFormat: 'mp3',
        aivisCloudOutputSamplingRate: 44100,
        aivisCloudUseSSML: true,
        onPlay: async (audioBuffer) => {
          fs.writeFileSync(outputPath, Buffer.from(audioBuffer));
        },
      });

      console.log(`Testing ${emotion} emotion (intensity: ${intensity})...`);
      await voiceService.speakText(text);
      console.log(`âœ“ Saved to: aivis-cloud-${emotion}.mp3`);
    }
    console.log('âœ“ Test 4 passed\n');
  } catch (error) {
    console.error('âŒ Test 4 failed:', error.message, '\n');
  }

  // Test 5: Different output formats
  console.log('=== Test 5: Output formats test ===');
  const formats = [
    { format: 'wav', extension: 'wav', description: 'PCMç„¡åœ§ç¸®' },
    { format: 'flac', extension: 'flac', description: 'å¯é€†åœ§ç¸®' },
    { format: 'mp3', extension: 'mp3', description: 'MP3ã‚³ãƒ¼ãƒ‡ãƒƒã‚¯' },
    { format: 'aac', extension: 'aac', description: 'AACã‚³ãƒ¼ãƒ‡ãƒƒã‚¯' },
  ];

  for (const { format, extension, description } of formats) {
    try {
      const outputPath = path.join(
        __dirname,
        `aivis-cloud-format.${extension}`,
      );

      const voiceService = new VoiceEngineAdapter({
        engineType: 'aivisCloud',
        speaker: 'a59cb814-0083-4369-8542-f51a29e72af7',
        apiKey: apiKey,
        aivisCloudOutputFormat: format,
        onPlay: async (audioBuffer) => {
          fs.writeFileSync(outputPath, Buffer.from(audioBuffer));
        },
      });

      console.log(`Testing ${format.toUpperCase()} format (${description})...`);
      await voiceService.speakText(`ã“ã‚Œã¯${format}å½¢å¼ã®ãƒ†ã‚¹ãƒˆã§ã™ã€‚`);
      console.log(`âœ“ Saved to: aivis-cloud-format.${extension}`);
    } catch (error) {
      console.error(`âŒ Failed for ${format}:`, error.message);
    }
  }

  console.log('\n=== Summary ===');
  console.log('âœ… Aivis Cloud API example completed!');
  console.log('\nâ„¹ï¸  Generated files can be played with:');
  console.log('- macOS: afplay filename.mp3');
  console.log('- Linux: aplay filename.wav');
  console.log('- Windows: start filename.mp3');
  console.log('\nâ„¹ï¸  Aivis Cloud API features:');
  console.log('- âœ… High-quality voice synthesis');
  console.log('- âœ… SSML support for rich expression');
  console.log('- âœ… Multiple output formats');
  console.log('- âœ… Emotional intensity control');
  console.log('- âœ… Real-time streaming capability');
  console.log('- âœ… Cloud-based (no local server required)');
  console.log('\nğŸ”— More info: https://aivis-project.com/cloud-api/');
}

// Custom audio handler example
async function advancedExample() {
  console.log('\n=== Advanced Example: Custom Audio Processing ===');

  const apiKey = process.env.AIVIS_CLOUD_API_KEY;
  if (!apiKey) {
    console.log('âš ï¸  Skipping advanced example (no API key)');
    return;
  }

  const options = {
    engineType: 'aivisCloud',
    speaker: 'a59cb814-0083-4369-8542-f51a29e72af7',
    apiKey: apiKey,

    // Advanced Aivis Cloud settings
    aivisCloudSpeakingRate: 1.1,
    aivisCloudEmotionalIntensity: 1.2,
    aivisCloudOutputFormat: 'flac', // High quality
    aivisCloudOutputSamplingRate: 48000,
    aivisCloudUseSSML: true,

    // Custom audio handler
    onPlay: async (audioBuffer) => {
      console.log(
        `Received high-quality audio: ${audioBuffer.byteLength} bytes`,
      );

      // Save with timestamp
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      const filename = `aivis-cloud-${timestamp}.flac`;
      const outputPath = path.join(__dirname, filename);

      fs.writeFileSync(outputPath, Buffer.from(audioBuffer));
      console.log(`âœ“ High-quality audio saved: ${filename}`);

      // Could also:
      // - Stream to audio server
      // - Process with audio effects
      // - Convert to different formats
      // - Analyze audio properties
    },

    onComplete: () => {
      console.log('âœ“ Advanced audio processing completed');
    },
  };

  try {
    const voiceService = new VoiceEngineAdapter(options);

    const advancedText = `
      <prosody rate="105%" pitch="+2%">
      Aivis Cloud APIã®é«˜åº¦ãªè¨­å®šä¾‹ã§ã™ã€‚
      </prosody>
      <break time="0.4s"/>
      <prosody rate="95%" volume="110%">
      æ„Ÿæƒ…è¡¨ç¾ã®å¼·ã•ã‚„è©±é€Ÿã‚’ç´°ã‹ãèª¿æ•´ã§ãã¾ã™ã€‚
      </prosody>
    `;

    await voiceService.speakText(advancedText);
    console.log('âœ… Advanced example completed!');
  } catch (error) {
    console.error('âŒ Advanced example failed:', error.message);
  }
}

// Run examples
async function runAll() {
  await main();
  await advancedExample();
}

if (require.main === module) {
  runAll().catch(console.error);
}
